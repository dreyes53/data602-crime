# -*- coding: utf-8 -*-
"""Final_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q363vrE9hdmvNRgEPdYOZDn0DWdlOBhP
"""

# !pip install geopandas descartes folium mapclassify prophet

# Download Map data for Prince George's (PG) County
import requests
import pandas as pd
import json
import matplotlib.pyplot as plt
from prophet import Prophet
import numpy as np
import sqlite3

# Get Historical Crime Incidents February 2017 to 5th July 2023 for PG county
conn = sqlite3.connect('historical_crime_data.db')
historical_df = pd.read_sql('SELECT * FROM crimes', conn)

# Get Crime Incidents July 2023 to Present and merge with Historical crime data
# Upcoming Weekly Schedule
# November 24, 2023
# Decemeber 1, 2023
# December 8, 2023

offset = 0
limit = 10000
full_present_crime_data = []

while True:
  url = f'https://data.princegeorgescountymd.gov/resource/xjru-idbe.json?$offset={offset}&$limit={limit}'
  x = requests.get(url)
  nested = json.loads(json.dumps(x.json(), indent=2))
  if len(nested) == 0:
    break
  full_present_crime_data = full_present_crime_data + nested
  offset = offset + limit

print("Number of Crime Incidents July 2023 to Present:", len(full_present_crime_data))
present_df = pd.json_normalize(full_present_crime_data)
present_df = present_df[present_df['location'].notna()]
present_df = present_df.drop(columns=['location'])

frames = [historical_df, present_df]
historical_df = pd.concat(frames, ignore_index=True)


historical_df['date']= pd.to_datetime(historical_df['date'])
historical_df['day_of_week'] = historical_df['date'].dt.dayofweek
historical_df['day_of_week'] = historical_df['day_of_week'].map({
    0: 'Monday',
    1: 'Tuesday',
    2: 'Wednesday',
    3: 'Thursday',
    4: 'Friday',
    5: 'Saturday',
    6: 'Sunday'
})
historical_df['latitude'] = pd.to_numeric(historical_df['latitude'])
historical_df['longitude'] = pd.to_numeric(historical_df['longitude'])

historical_df = historical_df[(historical_df['latitude'] > 30) & (historical_df['latitude'] < 40)]
historical_df = historical_df[(historical_df['longitude'] > -80) & (historical_df['longitude'] < -75)]

print("Number of Crime Incidents February 2017 to Present:", len(historical_df.index))

historical_df['date'] = pd.to_datetime(historical_df['date']).dt.date
df = historical_df.groupby('date').count()['clearance_code_inc_type'].to_frame()
df.reset_index(inplace=True)
df.columns = ['ds','y']
df.head()

# Prediction Model
# Predictions for Week, Month, Year
prediction_times = [7, 30, 365]

for prediction_period in prediction_times:
    # Make another copy of the data frame as m2
    df_m2 = df.copy()
    df_m2['ds'] = pd.to_datetime(df_m2['ds'])

    print(df_m2.dtypes)

    # Define the Upper Control Limit and Lower Control Limit as 3 standard deviations from the mean
    ucl = df_m2.mean() + df_m2.std()*3
    lcl = df_m2.mean() - df_m2.std()*3

    # Print the number of outliers found
    print('Above 3 standard deviations: ', df_m2[df_m2['y'] > ucl['y']]['y'].count(), 'entries')
    print('Below 3 standard deviations: ', df_m2[df_m2['y'] < lcl['y']]['y'].count(), 'entries')

    # Remove them by setting their value to None. Prophet says it can handle null values.
    df_m2.loc[df_m2['y'] > ucl['y'], 'y'] = None
    df_m2.loc[df_m2['y'] < lcl['y'], 'y'] = None

    # Log transformation
    df_m2['y'] = np.log(df_m2['y'])

    # Run Prophet using model 2
    m2_no_outlier = Prophet()
    m2_no_outlier.fit(df_m2)
    future = m2_no_outlier.make_future_dataframe(periods=prediction_period)
    forecast_m2 = m2_no_outlier.predict(future)

    m2_no_outlier.plot(forecast_m2)
    plt.xlabel('Date')
    plt.ylabel('Log(Crime Count)')
    plt.legend(['Actual', 'Trend', 'Uncertainty'])
    plt.title(f'PG County Crime Predictions for the next {prediction_period} days')
    plt.savefig(f'./plot_images/crime_prediction_{prediction_period}.jpg', bbox_inches='tight')

    start_day_of_predicted_week = forecast_m2["ds"].max() - pd.to_timedelta(prediction_period, unit='d')

    print("Forecast: ")
    # predicted_data = forecast_m2[forecast_m2['ds'] > start_day_of_predicted_week][['ds', 'yhat']]
    predicted_data = forecast_m2[forecast_m2['ds'] > start_day_of_predicted_week]

    fig = m2_no_outlier.plot_components(forecast_m2)
    fig.savefig(f'./plot_images/crime_trends_{prediction_period}.jpg', bbox_inches='tight')

    # First, let's get some useful variables: "y" for the actual value and "n" for the number of observations.
    y = df['y'].to_frame()
    y.index = df['ds']
    n = int(y.count())

    # Inverse the log
    forecast_m2_exp = np.exp(forecast_m2[['yhat','yhat_lower','yhat_upper']])
    forecast_m2_exp.index = forecast_m2['ds']

    # Calculate the error
    error = forecast_m2_exp['yhat'] - y['y']
    MAPE_m2 = (error/y['y']).abs().sum()/n *100
    print(round(MAPE_m2,2))
exit()